{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "109e52f4-46be-40e8-be96-0f49d39f45cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to train a new model? Press (Y) for Yes else (N) for No N\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download data from https://www.kaggle.com/datasets/sachinpatel21/az-handwritten-alphabets-in-csv-format\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import numpy as np \n",
    "import cv2 \n",
    "from collections import deque \n",
    "import time\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adadelta, SGD\n",
    "\n",
    "training = input(\"Do you want to train a new model? Press (Y) for Yes else (N) for No\")\n",
    "alpha = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "def generate_model():\n",
    "    model = Sequential([Conv2D(128,(3,3),activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1),padding='same'),\n",
    "                    Conv2D(64,(3,3),activation='relu', kernel_initializer='he_uniform',padding='same'),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    Conv2D(64,(3,3),activation='relu', kernel_initializer='he_uniform',padding='same'),\n",
    "                    Conv2D(64,(3,3),activation='relu', kernel_initializer='he_uniform',padding='same'),\n",
    "                    BatchNormalization(),\n",
    "                    MaxPooling2D(2,2),\n",
    "                    Flatten(),\n",
    "                    Dense(100,activation='relu',kernel_initializer='he_uniform'),\n",
    "                    Dropout(0.1),\n",
    "                    Dense(64,activation='relu',kernel_initializer='he_uniform'),\n",
    "                    Dropout(0.125),\n",
    "                    BatchNormalization(),\n",
    "                    Dense(26,activation='softmax')])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary() \n",
    "    return model\n",
    "\n",
    "def train():\n",
    "    \n",
    "    df=pd.read_csv('a_z_handwritten_data.csv')\n",
    "    data_array = np.array(df,dtype=np.uint8)\n",
    "    del df  #memory issues\n",
    "    \n",
    "    labels = data_array[:,0]\n",
    "    x = data_array[:,1:].reshape(372450,28,28)/255.\n",
    "    del data_array\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    list_alpha = list(zip(alpha, counts))\n",
    "\n",
    "    fig=plt.figure(figsize=(15,6))\n",
    "    plt.xlabel('ALPHABETS',fontsize=14)\n",
    "    plt.ylabel('COUNT',fontsize=14)\n",
    "    plt.bar(alpha,counts)\n",
    "\n",
    "    a = np.random.randint(low=0,high=372449,size=10)\n",
    "    fig=plt.figure(figsize=(30,30))\n",
    "    c=1\n",
    "    for i in a:\n",
    "        fig.add_subplot(20,20,c)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(x[i],cmap='gray')\n",
    "        c+=1\n",
    "        \n",
    "    del a   # cleaning\n",
    "    del c, list_alpha, counts, unique # cleaning\n",
    "\n",
    "    x=x.reshape(372450,28,28,1)\n",
    "    x_train,x_test,y_train,y_test = tts(x,labels,test_size=0.01)\n",
    "    del x  # memory issues\n",
    "    del labels\n",
    "\n",
    "    model = generate_model()\n",
    "    history = model.fit(x=x_train,y=y_train,validation_split=0.1,epochs=5)\n",
    "    \n",
    "    val_loss=history.history['val_loss']\n",
    "    val_accuracy=history.history['val_accuracy']\n",
    "    loss=history.history['loss']\n",
    "    accuracy=history.history['accuracy']\n",
    "\n",
    "    fig=plt.figure(figsize=(10,15))\n",
    "    fig.add_subplot(2, 1, 1)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(loss, color='blue', label='train')\n",
    "    plt.plot(val_loss, color='red', label='test')\n",
    "    plt.legend()\n",
    "    # plot accuracy\n",
    "    fig.add_subplot(2, 1, 2)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(accuracy, color='blue', label='train')\n",
    "    plt.plot(val_accuracy, color='red', label='test')\n",
    "    plt.legend()\n",
    "\n",
    "    metrics=model.evaluate(x_test,y_test)\n",
    "    metrics\n",
    "\n",
    "    model.save('Alphabet_Recognition.keras')\n",
    "\n",
    "if training == 'Y':\n",
    "    train()\n",
    "\n",
    "model = load_model('Alphabet_Recognition.keras')\n",
    "\n",
    "def color_detector():\n",
    "    def setValues(x):\n",
    "        print(\"\")\n",
    "    # creating a window for HUE selector\n",
    "    cv2.namedWindow(\"Color detectors\") \n",
    "    cv2.createTrackbar(\"Upper Hue\", \"Color detectors\", 153, 180, setValues) \n",
    "    cv2.createTrackbar(\"Upper Saturation\", \"Color detectors\", 255, 255, setValues) \n",
    "    cv2.createTrackbar(\"Upper Value\", \"Color detectors\", 255, 255, setValues) \n",
    "    cv2.createTrackbar(\"Lower Hue\", \"Color detectors\", 64, 180, setValues) \n",
    "    cv2.createTrackbar(\"Lower Saturation\", \"Color detectors\", 72, 255, setValues) \n",
    "    cv2.createTrackbar(\"Lower Value\", \"Color detectors\", 49, 255, setValues)\n",
    "\n",
    "def alphabet_recognize(filepath):\n",
    "    image = cv2.imread(filepath)\n",
    "    blur_image=cv2.medianBlur(image,7)\n",
    "\n",
    "    grey = cv2.cvtColor(blur_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    thresh = cv2.adaptiveThreshold(grey,200,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV,41,25)\n",
    "\n",
    "    contours,hierarchy= cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    preprocessed_digits = []\n",
    "\n",
    "    # initialize the reverse flag and sort index\n",
    "    # handle if we need to sort in reverse\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in contours]\n",
    "    (contours, boundingBoxes) = zip(*sorted(zip(contours, boundingBoxes),\n",
    "                                    key=lambda b:b[1][0], reverse=False))\n",
    "\n",
    "\n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "\n",
    "        # Creating a rectangle around the digit in the original image (for displaying the digits fetched via contours)\n",
    "        cv2.rectangle(blur_image, (x,y), (x+w, y+h), color=(255, 0, 0), thickness=2)\n",
    "\n",
    "        # Cropping out the digit from the image corresponding to the current contours in the for loop\n",
    "        digit = thresh[y:y+h, x:x+w]\n",
    "\n",
    "        # Resizing that digit to (18, 18)\n",
    "        resized_digit = cv2.resize(digit, (18,18))\n",
    "\n",
    "        # Padding the digit with 5 pixels of black color (zeros) in each side to finally produce the image of (28, 28)\n",
    "        padded_digit = np.pad(resized_digit, ((5,5),(5,5)), \"constant\", constant_values=0)\n",
    "\n",
    "        # Adding the preprocessed digit to the list of preprocessed digits\n",
    "        preprocessed_digits.append(padded_digit)\n",
    "\n",
    "    inp = np.array(preprocessed_digits)\n",
    "    i=1\n",
    "    alphabets=[]\n",
    "    for digit in preprocessed_digits:\n",
    "        [prediction] = model.predict(digit.reshape(1, 28, 28, 1)/255.)\n",
    "        pred=alpha[np.argmax(prediction)]\n",
    "        alphabets.append(pred)\n",
    "        i+=1\n",
    "        \n",
    "    print(\"The Recognized Alphabets are : \" ,*alphabets)\n",
    "    return \"\".join(alphabets)\n",
    "\n",
    "\n",
    "image_save_path = os.path.join(os.getcwd(), \"last_frame.jpg\")\n",
    "color_detector()\n",
    "\n",
    "bpoints = [deque(maxlen = 512)] \n",
    "gpoints = [deque(maxlen = 512)] \n",
    "ypoints = [deque(maxlen = 512)] \n",
    "rpoints = [deque(maxlen = 512)] \n",
    "\n",
    "# Now to mark the pointers in the above colour array we introduce some index values Which would mark their positions  \n",
    "\n",
    "blue_index = 0\n",
    "green_index = 0\n",
    "yellow_index = 0\n",
    "red_index = 0\n",
    "\n",
    "# The kernel is used for dilation of contour\n",
    "\n",
    "kernel = np.ones((5, 5)) \n",
    "\n",
    "# The ink colours for the drawing purpose \n",
    " \n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 225, 255), (0, 0, 255)] \n",
    "colorIndex = 0\n",
    "\n",
    "# Setting up the drawing board AKA The canvas \n",
    "\n",
    "paintWindow = np.zeros((1500, 1500, 3)) + 255\n",
    "\n",
    "cv2.namedWindow('Paint', cv2.WINDOW_AUTOSIZE) \n",
    " \n",
    "cap = cv2.VideoCapture(0) \n",
    "prediction = 'NA'\n",
    "pause = False\n",
    "while True: \n",
    "\n",
    "    # Reading the camera frame \n",
    "    ret, frame = cap.read() \n",
    "    # For saving\n",
    "    # out = cv2.VideoWriter(\"Paint-Window.mp4\", cv2.VideoWriter_fourcc(*'XVID'), 1, (frame.shape[1], frame.shape[0]))\n",
    "    \n",
    "    # Flipping the frame to see same side of the user  \n",
    "    frame = cv2.flip(frame, 1) \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) \n",
    "\n",
    "    # Getting the new positions of the trackbar and setting the new HSV values \n",
    "\n",
    "    u_hue = cv2.getTrackbarPos(\"Upper Hue\", \"Color detectors\") \n",
    "    u_saturation = cv2.getTrackbarPos(\"Upper Saturation\", \"Color detectors\") \n",
    "    u_value = cv2.getTrackbarPos(\"Upper Value\",\"Color detectors\") \n",
    "    l_hue = cv2.getTrackbarPos(\"Lower Hue\", \"Color detectors\") \n",
    "    l_saturation = cv2.getTrackbarPos(\"Lower Saturation\", \"Color detectors\") \n",
    "    l_value = cv2.getTrackbarPos(\"Lower Value\", \"Color detectors\") \n",
    "    Upper_hsv = np.array([u_hue, u_saturation, u_value]) \n",
    "    Lower_hsv = np.array([l_hue, l_saturation, l_value]) \n",
    "\n",
    "    # Adding the colour buttons to the live frame to choose color\n",
    "    frame = cv2.rectangle(frame, (35, 1), (135, 65), (122, 122, 122), -1) \n",
    "    frame = cv2.rectangle(frame, (160, 1), (255, 65), (255, 0, 0), -1) \n",
    "    frame = cv2.rectangle(frame, (275, 1), (370, 65), (0, 255, 0), -1) \n",
    "    frame = cv2.rectangle(frame, (390, 1), (485, 65), (0, 255, 255), -1) \n",
    "    frame = cv2.rectangle(frame, (505, 1), (600, 65), (0, 0, 255), -1) \n",
    "\n",
    "    cv2.putText(frame, \"Clear All\", (55, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 2, cv2.LINE_AA) \n",
    "\n",
    "    cv2.putText(frame, \"Blue Color\", (175, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 2, cv2.LINE_AA) \n",
    "    \n",
    "    cv2.putText(frame, \"Green Color\", (285, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 2, cv2.LINE_AA) \n",
    "\n",
    "    cv2.putText(frame, \"Yellow Color\", (400, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (150, 150, 150), 2, cv2.LINE_AA) \n",
    "\n",
    "    cv2.putText(frame, \"Red Color\", (520, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 2, cv2.LINE_AA) \n",
    "\n",
    "\n",
    "    # masking out the pointer for it's identification in the frame \n",
    "\n",
    "    Mask = cv2.inRange(hsv, Lower_hsv, Upper_hsv) \n",
    "    Mask = cv2.erode(Mask, kernel, iterations = 1) \n",
    "    Mask = cv2.morphologyEx(Mask, cv2.MORPH_OPEN, kernel) \n",
    "    Mask = cv2.dilate(Mask, kernel, iterations = 1) \n",
    "\n",
    "    # Now contouring the pointers post identification \n",
    "    lower_red = np.array([100,60,60])\n",
    "    upper_red = np.array([140,255,255])\n",
    "    red_mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    red_mask = cv2.erode(red_mask, kernel, iterations=1)\n",
    "    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel)\n",
    "    red_mask = cv2.dilate(red_mask, kernel, iterations=1)\n",
    "\n",
    "    countours = []\n",
    "    if pause == False:\n",
    "        countours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        centre = None\n",
    "\n",
    "    # If there are any contours formed \n",
    "    if len(countours) > 0 and pause == False: \n",
    "        \n",
    "        # sorting the contours for the biggest \n",
    "        countour = sorted(countours, key = cv2.contourArea, reverse = True)[0] \n",
    "        # Get the radius of the cirlce formed around the found contour   \n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(countour) \n",
    "        \n",
    "        # Drawing the circle boundary around the contour \n",
    "        cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2) \n",
    "        \n",
    "        # Calculating the centre of the detected contour \n",
    "        M = cv2.moments(countour) \n",
    "        centre = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00'])) \n",
    "        \n",
    "        # Now checking if the user clicked on another button on the screen (the 4 buttons that were mentioned Y,G,B,R and clear all)\n",
    "        if centre[1] <= 65: \n",
    "            \n",
    "            # Clear Button \n",
    "            if 35 <= centre[0] <= 135: \n",
    "                bpoints = [deque(maxlen = 512)] \n",
    "                gpoints = [deque(maxlen = 512)] \n",
    "                ypoints = [deque(maxlen = 512)] \n",
    "                rpoints = [deque(maxlen = 512)] \n",
    "\n",
    "                blue_index = 0\n",
    "                green_index = 0\n",
    "                yellow_index = 0\n",
    "                red_index = 0\n",
    "\n",
    "                paintWindow[67:, :, :] = 255\n",
    "            elif 160 <= centre[0] and centre[0] <= 255: \n",
    "                colorIndex = 0 # Blue \n",
    "                    \n",
    "            elif 275 <= centre[0] and centre[0] <= 370: \n",
    "                colorIndex = 1 # Green \n",
    "            elif 390 <= centre[0] and centre[0] <= 485: \n",
    "                colorIndex = 2 # Yellow\n",
    "            elif 505 <= centre[0] and centre[0] <= 600: \n",
    "                colorIndex = 3 # Red \n",
    "        else : \n",
    "            if colorIndex == 0: \n",
    "                bpoints[blue_index].appendleft(centre) \n",
    "            elif colorIndex == 1: \n",
    "                gpoints[green_index].appendleft(centre) \n",
    "            elif colorIndex == 2: \n",
    "                ypoints[yellow_index].appendleft(centre) \n",
    "            elif colorIndex == 3: \n",
    "                rpoints[red_index].appendleft(centre) \n",
    "                \n",
    "    # Appending the next deques if nothing is detected\n",
    "\n",
    "    else: \n",
    "        bpoints.append(deque(maxlen = 512)) \n",
    "        blue_index += 1\n",
    "        gpoints.append(deque(maxlen = 512)) \n",
    "        green_index += 1\n",
    "        ypoints.append(deque(maxlen = 512)) \n",
    "        yellow_index += 1\n",
    "        rpoints.append(deque(maxlen = 512)) \n",
    "        red_index += 1\n",
    "\n",
    "    # Drawing the lines of every colour on the canvas and the track frame window\n",
    "    \n",
    "    points = [bpoints, gpoints, ypoints, rpoints] \n",
    "    for i in range(len(points)): \n",
    "        for j in range(len(points[i])): \n",
    "            for k in range(1, len(points[i][j])): \n",
    "                if points[i][j][k - 1] is None or points[i][j][k] is None: \n",
    "                    continue\n",
    "                    \n",
    "                cv2.line(frame, points[i][j][k - 1], points[i][j][k], colors[i], 30) \n",
    "                # cv2.line(paintWindow, points[i][j][k - 1], points[i][j][k], colors[i], 30)\n",
    "                cv2.line(paintWindow, points[i][j][k - 1], points[i][j][k], (0, 0, 0), 30)\n",
    "\n",
    "    key = cv2.waitKey(1)    \n",
    "\n",
    "    # letter_predictor = LetterPredictor()        \n",
    "    if key & 0xFF == ord('v'):          \n",
    "        cv2.imwrite(image_save_path, paintWindow)\n",
    "        prediction = alphabet_recognize(image_save_path)\n",
    "\n",
    "    if key & 0xFF == ord('x'):          \n",
    "        pause = not pause\n",
    "\n",
    "    # letter_predictor = LetterPredictor()        \n",
    "    if key & 0xFF == ord('c'):           \n",
    "        bpoints = [deque(maxlen = 512)] \n",
    "        gpoints = [deque(maxlen = 512)] \n",
    "        ypoints = [deque(maxlen = 512)] \n",
    "        rpoints = [deque(maxlen = 512)] \n",
    "        blue_index = 0\n",
    "        green_index = 0\n",
    "        yellow_index = 0\n",
    "        red_index = 0\n",
    "        paintWindow[:, :, :] = 255\n",
    "        \n",
    "    cv2.putText(frame, \"Prediction: \" + str(prediction), (20,800), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,102,0), 8)\n",
    "    cv2.putText(frame, \"V to predict\", (1500,400), cv2.FONT_HERSHEY_SIMPLEX, 2, (102,51,0), 8)\n",
    "    cv2.putText(frame, \"C to Clear\", (1500,500), cv2.FONT_HERSHEY_SIMPLEX, 2, (102,51,0), 8)\n",
    "    cv2.putText(frame, \"Q to Quit\", (1500,600), cv2.FONT_HERSHEY_SIMPLEX, 2, (102,51,0), 8)\n",
    "    \n",
    "    # Displaying/running all the 3 windows \n",
    "    cv2.imshow(\"Live Tracking\", frame) \n",
    "    cv2.imshow(\"Paint\", paintWindow) \n",
    "    \n",
    "    # For quitting/breaking the loop - press and hold ctrl+q twice \n",
    "    if key & 0xFF == ord(\"q\"): \n",
    "        break\n",
    "\n",
    "# Releasing the camera and all the other resources of the device  \n",
    "cap.release() \n",
    "cv2.destroyAllWindows() \n",
    "key = cv2.waitKey(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3125596c-ba09-4a09-bb80-1d4100c973fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6b44b-1e17-43b2-9a3f-91f896e82553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
